{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "BP191yE3Xe4T",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BP191yE3Xe4T",
    "outputId": "853ca9c3-6c2d-4e88-88b1-fef7ae5ab4c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.1.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.14.0)\n",
      "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.2.2)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install gdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RIfKBjXtMrkH",
   "metadata": {
    "id": "RIfKBjXtMrkH"
   },
   "source": [
    "Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Q6aPjJH9XjoT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6aPjJH9XjoT",
    "outputId": "52fc1623-f45f-448f-eb63-16a4be42091e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1741Os55KZDupJpi7m-mOxmtq-dWg_3IA\n",
      "From (redirected): https://drive.google.com/uc?id=1741Os55KZDupJpi7m-mOxmtq-dWg_3IA&confirm=t&uuid=f417cd13-1a98-45f6-b97b-6a187a04cb55\n",
      "To: /content/competitionData.tar.gz\n",
      "100% 3.67G/3.67G [00:56<00:00, 64.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "#!gdown 1iSZwy5tkx9T0TZrB-0twEaf7jAadhXfS\n",
    "!gdown 1741Os55KZDupJpi7m-mOxmtq-dWg_3IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "zL-gXHuAYPOr",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zL-gXHuAYPOr",
    "outputId": "cf26eddc-36f6-4bd2-bc58-d6de233aa7cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./competitionData/\n",
      "./competitionData/competitionHoldOut/\n",
      "./competitionData/competitionHoldOut/t12.2022.05.24.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.14.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.07.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.07.27.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.08.02.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.28.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.08.11.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.21.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.07.14.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.16.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.07.21.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.08.13.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.05.26.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.07.05.mat\n",
      "./competitionData/competitionHoldOut/t12.2022.06.02.mat\n",
      "./competitionData/train/\n",
      "./competitionData/train/t12.2022.05.24.mat\n",
      "./competitionData/train/t12.2022.07.29.mat\n",
      "./competitionData/train/t12.2022.06.14.mat\n",
      "./competitionData/train/t12.2022.06.07.mat\n",
      "./competitionData/train/t12.2022.07.27.mat\n",
      "./competitionData/train/t12.2022.08.02.mat\n",
      "./competitionData/train/t12.2022.05.05.mat\n",
      "./competitionData/train/t12.2022.06.28.mat\n",
      "./competitionData/train/t12.2022.08.11.mat\n",
      "./competitionData/train/t12.2022.05.17.mat\n",
      "./competitionData/train/t12.2022.06.21.mat\n",
      "./competitionData/train/t12.2022.05.19.mat\n",
      "./competitionData/train/t12.2022.06.23.mat\n",
      "./competitionData/train/t12.2022.07.14.mat\n",
      "./competitionData/train/t12.2022.06.16.mat\n",
      "./competitionData/train/t12.2022.08.18.mat\n",
      "./competitionData/train/t12.2022.07.21.mat\n",
      "./competitionData/train/t12.2022.08.23.mat\n",
      "./competitionData/train/t12.2022.08.25.mat\n",
      "./competitionData/train/t12.2022.04.28.mat\n",
      "./competitionData/train/t12.2022.08.13.mat\n",
      "./competitionData/train/t12.2022.05.26.mat\n",
      "./competitionData/train/t12.2022.07.05.mat\n",
      "./competitionData/train/t12.2022.06.02.mat\n",
      "./competitionData/test/\n",
      "./competitionData/test/t12.2022.05.24.mat\n",
      "./competitionData/test/t12.2022.07.29.mat\n",
      "./competitionData/test/t12.2022.06.14.mat\n",
      "./competitionData/test/t12.2022.06.07.mat\n",
      "./competitionData/test/t12.2022.07.27.mat\n",
      "./competitionData/test/t12.2022.08.02.mat\n",
      "./competitionData/test/t12.2022.05.05.mat\n",
      "./competitionData/test/t12.2022.06.28.mat\n",
      "./competitionData/test/t12.2022.08.11.mat\n",
      "./competitionData/test/t12.2022.05.17.mat\n",
      "./competitionData/test/t12.2022.06.21.mat\n",
      "./competitionData/test/t12.2022.05.19.mat\n",
      "./competitionData/test/t12.2022.06.23.mat\n",
      "./competitionData/test/t12.2022.07.14.mat\n",
      "./competitionData/test/t12.2022.06.16.mat\n",
      "./competitionData/test/t12.2022.08.18.mat\n",
      "./competitionData/test/t12.2022.07.21.mat\n",
      "./competitionData/test/t12.2022.08.23.mat\n",
      "./competitionData/test/t12.2022.08.25.mat\n",
      "./competitionData/test/t12.2022.04.28.mat\n",
      "./competitionData/test/t12.2022.08.13.mat\n",
      "./competitionData/test/t12.2022.05.26.mat\n",
      "./competitionData/test/t12.2022.07.05.mat\n",
      "./competitionData/test/t12.2022.06.02.mat\n"
     ]
    }
   ],
   "source": [
    "!tar -xzvf \"competitionData.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b6cc836",
   "metadata": {
    "id": "0b6cc836"
   },
   "outputs": [],
   "source": [
    "sessionNames = ['t12.2022.04.28',  't12.2022.05.26',  't12.2022.06.21', 't12.2022.07.21',  't12.2022.08.13',\n",
    "'t12.2022.05.05',  't12.2022.06.02',  't12.2022.06.23',  't12.2022.07.27',  't12.2022.08.18',\n",
    "'t12.2022.05.17',  't12.2022.06.07',  't12.2022.06.28',  't12.2022.07.29',  't12.2022.08.23',\n",
    "'t12.2022.05.19',  't12.2022.06.14',  't12.2022.07.05',  't12.2022.08.02',  't12.2022.08.25',\n",
    "'t12.2022.05.24',  't12.2022.06.16',  't12.2022.07.14',  't12.2022.08.11']\n",
    "sessionNames.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "337bd590",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "337bd590",
    "outputId": "10068870-4d69-463b-bbde-47bb106bca9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting g2p_en\n",
      "  Downloading g2p_en-2.1.0-py3-none-any.whl (3.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (1.25.2)\n",
      "Requirement already satisfied: nltk>=3.2.4 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (3.8.1)\n",
      "Requirement already satisfied: inflect>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from g2p_en) (7.0.0)\n",
      "Collecting distance>=0.1.3 (from g2p_en)\n",
      "  Downloading Distance-0.1.3.tar.gz (180 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.3/180.3 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: pydantic>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p_en) (2.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from inflect>=0.3.1->g2p_en) (4.11.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (8.1.7)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (2024.5.15)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.2.4->g2p_en) (4.66.4)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=0.3.1->g2p_en) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9.1->inflect>=0.3.1->g2p_en) (2.18.2)\n",
      "Building wheels for collected packages: distance\n",
      "  Building wheel for distance (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for distance: filename=Distance-0.1.3-py3-none-any.whl size=16258 sha256=780c35e8faf239c878829ddf179b507ac9d7470a11317dd51de1d45e58c9ae60\n",
      "  Stored in directory: /root/.cache/pip/wheels/e8/bb/de/f71bf63559ea9a921059a5405806f7ff6ed612a9231c4a9309\n",
      "Successfully built distance\n",
      "Installing collected packages: distance, g2p_en\n",
      "Successfully installed distance-0.1.3 g2p_en-2.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install g2p_en"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RWsq22ZlkOAo",
   "metadata": {
    "id": "RWsq22ZlkOAo"
   },
   "source": [
    "Data preparation From baseline algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae1be0fe",
   "metadata": {
    "id": "ae1be0fe"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "edb2175e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "edb2175e",
    "outputId": "84f86245-61ff-423d-fba9-551f93f8a71c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package cmudict to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/cmudict.zip.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from g2p_en import G2p\n",
    "import numpy as np\n",
    "\n",
    "g2p = G2p()\n",
    "PHONE_DEF = [\n",
    "    'AA', 'AE', 'AH', 'AO', 'AW',\n",
    "    'AY', 'B',  'CH', 'D', 'DH',\n",
    "    'EH', 'ER', 'EY', 'F', 'G',\n",
    "    'HH', 'IH', 'IY', 'JH', 'K',\n",
    "    'L', 'M', 'N', 'NG', 'OW',\n",
    "    'OY', 'P', 'R', 'S', 'SH',\n",
    "    'T', 'TH', 'UH', 'UW', 'V',\n",
    "    'W', 'Y', 'Z', 'ZH'\n",
    "]\n",
    "PHONE_DEF_SIL = PHONE_DEF + ['SIL']\n",
    "\n",
    "def phoneToId(p):\n",
    "    return PHONE_DEF_SIL.index(p)\n",
    "\n",
    "def IdToPhone(p):\n",
    "    return PHONE_DEF_SIL.index(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20398fe1",
   "metadata": {
    "id": "20398fe1"
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def loadFeaturesAndNormalize(sessionPath):\n",
    "\n",
    "    dat = scipy.io.loadmat(sessionPath)\n",
    "\n",
    "    input_features = []\n",
    "    transcriptions = []\n",
    "    frame_lens = []\n",
    "    block_means = []\n",
    "    block_stds = []\n",
    "    n_trials = dat['sentenceText'].shape[0]\n",
    "\n",
    "    #collect area 6v tx1 and spikePow features\n",
    "    for i in range(n_trials):\n",
    "\n",
    "#         features = np.concatenate([dat['tx1'][0,i][:,0:128], dat['spikePow'][0,i][:,0:128]], axis=1)\n",
    "        features = np.array(dat['tx1'][0,i][:,0:128]) * np.array(dat['spikePow'][0,i][:,0:128])\n",
    "\n",
    "\n",
    "        sentence_len = features.shape[0]\n",
    "        sentence = dat['sentenceText'][i].strip()\n",
    "\n",
    "        input_features.append(features)\n",
    "        transcriptions.append(sentence)\n",
    "        frame_lens.append(sentence_len)\n",
    "\n",
    "    #block-wise feature normalization\n",
    "    blockNums = np.squeeze(dat['blockIdx'])\n",
    "    blockList = np.unique(blockNums)\n",
    "    blocks = []\n",
    "    for b in range(len(blockList)):\n",
    "        sentIdx = np.argwhere(blockNums==blockList[b])\n",
    "        sentIdx = sentIdx[:,0].astype(np.int32)\n",
    "        blocks.append(sentIdx)\n",
    "\n",
    "    for b in range(len(blocks)):\n",
    "        feats = np.concatenate(input_features[blocks[b][0]:(blocks[b][-1]+1)], axis=0)\n",
    "        feats_mean = np.mean(feats, axis=0, keepdims=True)\n",
    "        feats_std = np.std(feats, axis=0, keepdims=True)\n",
    "        for i in blocks[b]:\n",
    "            input_features[i] = (input_features[i] - feats_mean) / (feats_std + 1e-8)\n",
    "\n",
    "    #convert to tfRecord file\n",
    "    session_data = {\n",
    "        'inputFeatures': input_features,\n",
    "        'transcriptions': transcriptions,\n",
    "        'frameLens': frame_lens\n",
    "    }\n",
    "\n",
    "    return session_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1cf55fa2",
   "metadata": {
    "id": "1cf55fa2"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def getDataset(fileName):\n",
    "    session_data = loadFeaturesAndNormalize(fileName)\n",
    "\n",
    "    allDat = []\n",
    "    trueSentences = []\n",
    "    seqElements = []\n",
    "\n",
    "    for x in range(len(session_data['inputFeatures'])):\n",
    "        allDat.append(session_data['inputFeatures'][x])\n",
    "        trueSentences.append(session_data['transcriptions'][x])\n",
    "\n",
    "        thisTranscription = str(session_data['transcriptions'][x]).strip()\n",
    "        thisTranscription = re.sub(r'[^a-zA-Z\\- \\']', '', thisTranscription)\n",
    "        thisTranscription = thisTranscription.replace('--', '').lower()\n",
    "        addInterWordSymbol = True\n",
    "\n",
    "        phonemes = []\n",
    "        for p in g2p(thisTranscription):\n",
    "            if addInterWordSymbol and p==' ':\n",
    "                phonemes.append('SIL')\n",
    "            p = re.sub(r'[0-9]', '', p)  # Remove stress\n",
    "            if re.match(r'[A-Z]+', p):  # Only keep phonemes\n",
    "                phonemes.append(p)\n",
    "\n",
    "        #add one SIL symbol at the end so there's one at the end of each word\n",
    "        if addInterWordSymbol:\n",
    "            phonemes.append('SIL')\n",
    "\n",
    "        seqLen = len(phonemes)\n",
    "        maxSeqLen = 128\n",
    "        seqClassIDs = np.zeros([maxSeqLen]).astype(np.int32)\n",
    "        seqClassIDs[0:seqLen] = [phoneToId(p) + 1 for p in phonemes]\n",
    "        seqElements.append(seqClassIDs)\n",
    "\n",
    "    newDataset = {}\n",
    "    newDataset['sentenceDat'] = allDat\n",
    "    newDataset['transcriptions'] = trueSentences\n",
    "#     newDataset['phonemes'] = seqElements\n",
    "\n",
    "    timeSeriesLens = []\n",
    "#     phoneLens = []\n",
    "    for x in range(len(newDataset['sentenceDat'])):\n",
    "        timeSeriesLens.append(newDataset['sentenceDat'][x].shape[0])\n",
    "\n",
    "    newDataset['timeSeriesLens'] = np.array(timeSeriesLens)\n",
    "\n",
    "    return pd.DataFrame.from_dict(newDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "815eca0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "815eca0e",
    "outputId": "64cb1cdf-7cbf-4d6f-bf0e-69dd1b1d666a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "trainDatasets = pd.DataFrame()\n",
    "testDatasets = pd.DataFrame()\n",
    "competitionDatasets = []\n",
    "\n",
    "dataDir = './competitionData'\n",
    "\n",
    "for dayIdx in range(len(sessionNames)):\n",
    "    print(dayIdx)\n",
    "    trainDataset = getDataset(dataDir + '/train/' + sessionNames[dayIdx] + '.mat')\n",
    "    testDataset = getDataset(dataDir + '/test/' + sessionNames[dayIdx] + '.mat')\n",
    "    trainDatasets = pd.concat([trainDatasets,trainDataset],ignore_index=True)\n",
    "    testDatasets = pd.concat([testDatasets,testDataset],ignore_index=True)\n",
    "\n",
    "    if os.path.exists(dataDir + '/competitionHoldOut/' + sessionNames[dayIdx] + '.mat'):\n",
    "        dataset = getDataset(dataDir + '/competitionHoldOut/' + sessionNames[dayIdx] + '.mat')\n",
    "        competitionDatasets.append(dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de32e23e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "de32e23e",
    "outputId": "fe8c3535-f23c-4e03-b9e6-c481a678666b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 18, 19, 20]\n"
     ]
    }
   ],
   "source": [
    "dataDir = './competitionData'\n",
    "\n",
    "competitionDays = []\n",
    "for dayIdx in range(len(sessionNames)):\n",
    "    if os.path.exists(dataDir + '/competitionHoldOut/' + sessionNames[dayIdx] + '.mat'):\n",
    "        competitionDays.append(dayIdx)\n",
    "print(competitionDays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80014502",
   "metadata": {
    "id": "80014502"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "allDatasets = {}\n",
    "allDatasets['train'] = trainDatasets\n",
    "allDatasets['test'] = testDatasets\n",
    "allDatasets['competition'] = competitionDatasets\n",
    "\n",
    "with open(dataDir+'/Datasets', 'wb') as handle:\n",
    "    pickle.dump(allDatasets, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d7a9418c",
   "metadata": {
    "id": "d7a9418c"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9f35e5",
   "metadata": {
    "id": "4c9f35e5"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8cf1348",
   "metadata": {
    "id": "a8cf1348"
   },
   "outputs": [],
   "source": [
    "# !python -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e08d4a57",
   "metadata": {
    "id": "e08d4a57"
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "# from torchtext.data import Field, BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "375c9395",
   "metadata": {
    "id": "375c9395"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "INPUT_DIM = 1135#\n",
    "OUTPUT_DIM = 127#\n",
    "ENC_EMB_DIM = 128#\n",
    "DEC_EMB_DIM = 128#\n",
    "ENC_HID_DIM = 256#\n",
    "DEC_HID_DIM = 256#\n",
    "N_LAYERS = 1\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "BATCH_SIZE = 10 #20\n",
    "SOS = 35 #(#)\n",
    "EOS = 64 #(@)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "262fa7fb",
   "metadata": {
    "id": "262fa7fb"
   },
   "outputs": [],
   "source": [
    "def createBatch(df): #make the same length\n",
    "    max_time = 1024\n",
    "    df = np.append(df, [[0 for k in range(128)] for j in range(max_time - df.shape[0])], axis=0)\n",
    "    return df\n",
    "def create_sentences(sent):\n",
    "    max_time = 128\n",
    "    sent = np.append(sent, [0 for j in range(max_time - sent.shape[0])], axis=0)\n",
    "    return sent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "68c55f7d",
   "metadata": {
    "id": "68c55f7d"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "q8FtK41lhY3a",
   "metadata": {
    "id": "q8FtK41lhY3a"
   },
   "outputs": [],
   "source": [
    "punctuation_txt = [' ',',', '`', '-', '!', '?', '.', ':',';',\"'\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "77f2dfe7",
   "metadata": {
    "id": "77f2dfe7"
   },
   "outputs": [],
   "source": [
    "class BrainDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_name = 'sentenceDat'\n",
    "        self.df = df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df['transcriptions'][idx]\n",
    "        brainDatRaw = self.df['sentenceDat'][idx]\n",
    "        brainDatRaw = createBatch(brainDatRaw)\n",
    "\n",
    "        target = [ord(i.lower()) for i in text if i not in punctuation_txt]\n",
    "        target.insert(0,SOS)\n",
    "        target.insert(-1,EOS)\n",
    "        target=target[::-1] #sentence chars to didits\n",
    "        target= create_sentences(np.array(target))\n",
    "\n",
    "        return {\"brain\":brainDatRaw, \"target\": target}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3113cc49",
   "metadata": {
    "id": "3113cc49"
   },
   "outputs": [],
   "source": [
    "trainDs = BrainDataset(trainDatasets)\n",
    "testDS = BrainDataset(testDatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef297ca1",
   "metadata": {
    "id": "ef297ca1"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(trainDs, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(testDS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb90a755",
   "metadata": {
    "id": "eb90a755"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a1dce539",
   "metadata": {
    "id": "a1dce539"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = nn.Conv2d(1, 1, (1,4))\n",
    "        self.pool = nn.MaxPool2d(kernel_size=(1,4))\n",
    "\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.input_dim = input_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, n_layers, dropout=dropout,\n",
    "                          bidirectional=True)\n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "\n",
    "    def forward(self, src_batch):\n",
    "        x = self.pool(F.leaky_relu(self.conv(src_batch)))\n",
    "        x= self.pool(F.leaky_relu(self.conv(x)))\n",
    "        x = self.pool(F.leaky_relu(self.conv(x)))\n",
    "        x= x.to(torch.int64)\n",
    "        x= x.squeeze()\n",
    "        x = torch.permute(x,(1,0))\n",
    "\n",
    "        ## Add SOS = 35 (#) and EOS = 64 (@)\n",
    "        sos = torch.Tensor([[35]*BATCH_SIZE]).to(device)\n",
    "        eos = sos = torch.Tensor([[64]*BATCH_SIZE]).to(device)\n",
    "        x = torch.cat((sos,x,eos), dim=0).to(torch.int64).to(device)\n",
    "        # src [sent len, batch size]\n",
    "        embedded = self.embedding(x) # [sent len, batch size, emb dim]\n",
    "        outputs, hidden = self.rnn(embedded)  # [sent len, batch size, hidden dim]\n",
    "        # outputs -> [sent len, batch size, hidden dim * n directions]\n",
    "        # hidden -> [n layers * n directions, batch size, hidden dim]\n",
    "\n",
    "\n",
    "        # initial decoder hidden is final hidden state of the forwards and\n",
    "        # backwards encoder RNNs fed through a linear layer\n",
    "        concated = torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1)\n",
    "\n",
    "        hidden = torch.tanh(self.fc(concated))\n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f09aa2e1",
   "metadata": {
    "id": "f09aa2e1"
   },
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "\n",
    "        # enc_hid_dim multiply by 2 due to bidirectional\n",
    "        self.fc1 = nn.Linear(enc_hid_dim * 2 + dec_hid_dim, dec_hid_dim)\n",
    "        self.fc2 = nn.Linear(dec_hid_dim, 1, bias=False)\n",
    "\n",
    "    def forward(self, encoder_outputs, hidden):\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "\n",
    "        # repeat encoder hidden state src_len times [batch size, sent len, dec hid dim]\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "        # reshape/permute the encoder output, so that the batch size comes first\n",
    "        # [batch size, sent len, enc hid dim * 2], times 2 because of bidirectional\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # the attention mechanism receives a concatenation of the hidden state\n",
    "        # and the encoder output\n",
    "\n",
    "        concat = torch.cat((hidden, outputs), dim=2)\n",
    "\n",
    "        # fully connected layer and softmax layer to compute the attention weight\n",
    "        # [batch size, sent len, dec hid dim]\n",
    "        energy = torch.tanh(self.fc1(concat))\n",
    "\n",
    "        # attention weight should be of [batch size, sent len]\n",
    "        attention = self.fc2(energy).squeeze(dim=2)\n",
    "        attention_weight = torch.softmax(attention, dim=1)\n",
    "        return attention_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "68be7d81",
   "metadata": {
    "id": "68be7d81"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, n_layers,\n",
    "                 dropout, attention):\n",
    "        super().__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.enc_hid_dim = enc_hid_dim\n",
    "        self.dec_hid_dim = dec_hid_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        self.attention = attention\n",
    "\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.rnn = nn.GRU(enc_hid_dim * 2 + emb_dim, dec_hid_dim, n_layers, dropout=dropout)\n",
    "        self.linear = nn.Linear(dec_hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, trg, encoder_outputs, hidden):\n",
    "        # trg [batch size]\n",
    "        # outputs [src sen len, batch size, enc hid dim * 2], times 2 due to bidirectional\n",
    "        # hidden [batch size, dec hid dim]\n",
    "\n",
    "        # [batch size, 1, sent len]\n",
    "        attention = self.attention(encoder_outputs, hidden).unsqueeze(1)\n",
    "\n",
    "        # [batch size, sent len, enc hid dim * 2]\n",
    "        outputs = encoder_outputs.permute(1, 0, 2)\n",
    "\n",
    "        # [1, batch size, enc hid dim * 2]\n",
    "        context = torch.bmm(attention, outputs).permute(1, 0, 2)\n",
    "\n",
    "        # input sentence -> embedding\n",
    "        # [1, batch size, emb dim]\n",
    "        embedded = self.embedding(trg.unsqueeze(0))\n",
    "        rnn_input = torch.cat((embedded, context), dim=2)\n",
    "\n",
    "        outputs, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        prediction = self.linear(outputs.squeeze(0))\n",
    "        return prediction, hidden.squeeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "088ecb7a",
   "metadata": {
    "id": "088ecb7a"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, src_batch, trg_batch, teacher_forcing_ratio=0.5):\n",
    "        max_len, batch_size = trg_batch.shape\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "\n",
    "        # tensor to store decoder's output\n",
    "        outputs = torch.zeros(max_len, batch_size, trg_vocab_size).to(self.device)\n",
    "\n",
    "        # encoder_outputs : all hidden states of the input sequence (forward and backward)\n",
    "        # hidden : final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src_batch)\n",
    "\n",
    "        trg = trg_batch[0]\n",
    "        # tt = torch.transpose(trg_batch,1,0)[0]\n",
    "        # tar_srt = [chr(it) for it in tt]\n",
    "        # print(\"S2S\", f\"{''.join(tar_srt)}\")\n",
    "        # stri = [chr(trg[0])]\n",
    "        for i in range(1, max_len):\n",
    "            # stri.append(chr(trg[0]))\n",
    "            prediction, hidden = self.decoder(trg, encoder_outputs, hidden)\n",
    "            # print(\"S2S_pred\", prediction.shape)\n",
    "            outputs[i] = prediction\n",
    "\n",
    "            if random.random() < teacher_forcing_ratio:\n",
    "                trg = trg_batch[i]\n",
    "            else:\n",
    "                trg = prediction.argmax(1)\n",
    "                # print(\"trg\", trg)\n",
    "        # print(f\"pred: {''.join(stri)}\")\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3e3517e9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3e3517e9",
    "outputId": "8c162c38-b7dc-4035-b56b-7421e31fd8a4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (conv): Conv2d(1, 1, kernel_size=(1, 4), stride=(1, 1))\n",
       "    (pool): MaxPool2d(kernel_size=(1, 4), stride=(1, 4), padding=0, dilation=1, ceil_mode=False)\n",
       "    (embedding): Embedding(1135, 128)\n",
       "    (rnn): GRU(128, 256, dropout=0.5, bidirectional=True)\n",
       "    (fc): Linear(in_features=512, out_features=256, bias=True)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (attention): Attention(\n",
       "      (fc1): Linear(in_features=768, out_features=256, bias=True)\n",
       "      (fc2): Linear(in_features=256, out_features=1, bias=False)\n",
       "    )\n",
       "    (embedding): Embedding(127, 128)\n",
       "    (rnn): GRU(640, 256, dropout=0.5)\n",
       "    (linear): Linear(in_features=256, out_features=127, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = Attention(ENC_HID_DIM, DEC_HID_DIM)\n",
    "encoder = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, ENC_DROPOUT)\n",
    "decoder = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, N_LAYERS, DEC_DROPOUT, attention)\n",
    "seq2seq = Seq2Seq(encoder, decoder, device).to(device)\n",
    "seq2seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a562a6e",
   "metadata": {
    "id": "8a562a6e"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1ec9e66",
   "metadata": {
    "id": "f1ec9e66"
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "222da713",
   "metadata": {
    "id": "222da713"
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(seq2seq.parameters())\n",
    "\n",
    "# ignore the padding index when calculating the loss\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=101).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d6cca2d9",
   "metadata": {
    "id": "d6cca2d9"
   },
   "outputs": [],
   "source": [
    "def train(seq2seq, iterator, optimizer, criterion):\n",
    "    seq2seq.train()\n",
    "\n",
    "    epoch_acc  = 0\n",
    "    epoch_loss = 0\n",
    "    for batch in iterator:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        brain = np.round(batch[\"brain\"],2)[:,None,:,:].type(torch.float).to(device)\n",
    "        tg = torch.transpose(batch[\"target\"],1,0).to(device)\n",
    "\n",
    "\n",
    "        outputs =seq2seq(brain, tg)\n",
    "\n",
    "        # the loss function only works on 2d inputs\n",
    "        # and 1d targets we need to flatten each of them\n",
    "        outputs_flatten = outputs[1:].view(-1, outputs.shape[-1]).to(device)\n",
    "        trg_flatten = tg[1:].contiguous().view(-1).to(device)\n",
    "\n",
    "        logits = torch.argmax(outputs, dim=2).type(torch.float).to(device)\n",
    "        loss = criterion(outputs_flatten, trg_flatten)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_acc += torch.mean((logits == tg).type(torch.float))\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "39a9aa4c",
   "metadata": {
    "id": "39a9aa4c"
   },
   "outputs": [],
   "source": [
    "def evaluate(seq2seq, iterator, criterion):\n",
    "    seq2seq.eval()\n",
    "\n",
    "    epoch_acc  = 0\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in iterator:\n",
    "            # turn off teacher forcing\n",
    "            brain = np.round(batch[\"brain\"],2)[:,None,:,:].type(torch.float).to(device)\n",
    "            tg = torch.transpose(batch[\"target\"],1,0).to(device)\n",
    "\n",
    "\n",
    "            outputs =seq2seq(brain, tg, teacher_forcing_ratio=0)\n",
    "\n",
    "            # trg = [trg sent len, batch size]\n",
    "            # output = [trg sent len, batch size, output dim]\n",
    "            outputs_flatten = outputs[1:].view(-1, outputs.shape[-1]).to(device)\n",
    "            trg_flatten = tg[1:].contiguous().view(-1).to(device)\n",
    "\n",
    "            logits = torch.argmax(outputs, dim=2).type(torch.float).to(device)\n",
    "            loss = criterion(outputs_flatten, trg_flatten)\n",
    "\n",
    "            epoch_acc += torch.mean((logits == tg).type(torch.float))\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6257e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01\n",
      "\tTrain Loss: 0.930\n",
      "\t Val. Loss: 0.929\n",
      "Epoch: 02\n",
      "\tTrain Loss: 0.934\n",
      "\t Val. Loss: 0.951\n",
      "Epoch: 03\n",
      "\tTrain Loss: 0.986\n",
      "\t Val. Loss: 0.997\n",
      "Epoch: 04\n",
      "\tTrain Loss: 0.931\n",
      "\t Val. Loss: 0.914\n",
      "Epoch: 05\n",
      "\tTrain Loss: 0.918\n",
      "\t Val. Loss: 0.939\n",
      "Epoch: 06\n",
      "\tTrain Loss: 0.834\n",
      "\t Val. Loss: 0.999\n",
      "Epoch: 07\n",
      "\tTrain Loss: 0.875\n",
      "\t Val. Loss: 0.920\n",
      "Epoch: 08\n",
      "\tTrain Loss: 0.845\n",
      "\t Val. Loss: 0.947\n",
      "Epoch: 09\n",
      "\tTrain Loss: 0.856\n",
      "\t Val. Loss: 0.918\n",
      "Epoch: 10\n",
      "\tTrain Loss: 0.839\n",
      "\t Val. Loss: 0.969\n",
      "Epoch: 11\n",
      "\tTrain Loss: 0.854\n",
      "\t Val. Loss: 0.991\n",
      "Epoch: 12\n",
      "\tTrain Loss: 0.868\n",
      "\t Val. Loss: 0.927\n",
      "Epoch: 13\n",
      "\tTrain Loss: 0.896\n",
      "\t Val. Loss: 0.974\n",
      "Epoch: 14\n",
      "\tTrain Loss: 0.608\n",
      "\t Val. Loss: 0.850\n",
      "Epoch: 15\n",
      "\tTrain Loss: 0.629\n",
      "\t Val. Loss: 0.829\n",
      "Epoch: 16\n",
      "\tTrain Loss: 0.653\n",
      "\t Val. Loss: 0.857\n",
      "Epoch: 17\n",
      "\tTrain Loss: 0.687\n",
      "\t Val. Loss: 0.834\n",
      "Epoch: 18\n",
      "\tTrain Loss: 0.668\n",
      "\t Val. Loss: 0.845\n",
      "Epoch: 19\n",
      "\tTrain Loss: 0.691\n",
      "\t Val. Loss: 0.825\n",
      "Epoch: 20\n",
      "\tTrain Loss: 0.662\n",
      "\t Val. Loss: 0.819\n",
      "Epoch: 21\n",
      "\tTrain Loss: 0.604\n",
      "\t Val. Loss: 0.894\n",
      "Epoch: 22\n",
      "\tTrain Loss: 0.679\n",
      "\t Val. Loss: 0.900\n",
      "Epoch: 23\n",
      "\tTrain Loss: 0.646\n",
      "\t Val. Loss: 0.865\n",
      "Epoch: 24\n",
      "\tTrain Loss: 0.661\n",
      "\t Val. Loss: 0.730\n",
      "Epoch: 25\n",
      "\tTrain Loss: 0.655\n",
      "\t Val. Loss: 0.742\n",
      "Epoch: 26\n",
      "\tTrain Loss: 0.684\n",
      "\t Val. Loss: 0.795\n",
      "Epoch: 27\n",
      "\tTrain Loss: 0.696\n",
      "\t Val. Loss: 0.749\n",
      "Epoch: 28\n",
      "\tTrain Loss: 0.604\n",
      "\t Val. Loss: 0.765\n",
      "Epoch: 29\n",
      "\tTrain Loss: 0.668\n",
      "\t Val. Loss: 0.736\n",
      "Epoch: 30\n",
      "\tTrain Loss: 0.639\n",
      "\t Val. Loss: 0.736\n"
     ]
    }
   ],
   "source": [
    "N_EPOCHS = 30\n",
    "best_valid_loss = float('inf')\n",
    "train_loses =[]\n",
    "test_loses =[]\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "    train_loss, train_acc = train(seq2seq, train_dataloader, optimizer, criterion)\n",
    "    valid_loss, val_acc = evaluate(seq2seq, test_dataloader, criterion)\n",
    "    end_time = time.time()\n",
    "\n",
    "    train_loses.append(train_loss)\n",
    "    test_loses.append(valid_loss)\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(seq2seq.state_dict(), 'tut2-model.pt')\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02}')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c624c9b0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c624c9b0",
    "outputId": "b7463b90-a078-4a28-94a7-f76c984e7574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 10, 127])\n"
     ]
    }
   ],
   "source": [
    "for j in train_dataloader:\n",
    "    break\n",
    "\n",
    "brain = np.round(j[\"brain\"],2)[:,None,:,:].type(torch.float).to(device)\n",
    "tg = torch.transpose(j[\"target\"],1,0).to(device)\n",
    "\n",
    "seq2seq.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = seq2seq(brain, tg, teacher_forcing_ratio=0)\n",
    "\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "tW5U4My__ViC",
   "metadata": {
    "id": "tW5U4My__ViC"
   },
   "outputs": [],
   "source": [
    "def calculate_wer(decoded_sentences, true_sentences):\n",
    "    total_word_errors = 0\n",
    "    total_words = 0\n",
    "\n",
    "    for decoded_sent, true_sent in zip(decoded_sentences, true_sentences):\n",
    "        decoded_words = decoded_sent.split(\" \")\n",
    "        true_words = true_sent.split(\" \")\n",
    "        word_errors = editdistance.eval(decoded_words, true_words)\n",
    "        total_word_errors += word_errors\n",
    "        total_words += len(true_words)\n",
    "\n",
    "    wer = total_word_errors / total_words\n",
    "    return wer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62295a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.2584\n"
     ]
    }
   ],
   "source": [
    "wer = calculate_wer(outputs.argmax(2),tg)\n",
    "print(np.round(wer,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "sS_ZT4D1ju-W",
   "metadata": {
    "id": "sS_ZT4D1ju-W"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfada462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
